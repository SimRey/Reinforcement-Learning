{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "green-recommendation",
   "metadata": {},
   "source": [
    "## <center> Q-Learning - Discrete Actions</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "billion-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b461afe9",
   "metadata": {},
   "source": [
    "### PART 1: \n",
    "\n",
    "Setting up Frozen Lake Environment\n",
    "\n",
    "The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\n",
    "\n",
    "The surface is described using a grid like the following:\n",
    "\n",
    "    S | F | F | F\n",
    "    - - - - - - -\n",
    "    F | H | F | H\n",
    "    - - - - - - -\n",
    "    F | F | F | H\n",
    "    - - - - - - -\n",
    "    H | F | F | G  \n",
    "\n",
    "- S: starting point, safe \n",
    "- F: frozen surface, safe)\n",
    "- H: hole, fall to your doom)\n",
    "- G: goal, where the frisbee is located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e55db",
   "metadata": {},
   "source": [
    "#### Environment set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdd8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "\n",
    "try:\n",
    "\n",
    "    register(\n",
    "        id='FrozenLakeNotSlippery-v0', # make sure this is a custom name!\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "        max_episode_steps=100, # if goal not completed stops after this number of episodes\n",
    "        reward_threshold=.8196, # optimum = .8196 --> not useful for binary goals\n",
    "    )\n",
    "except:\n",
    "    print('You probably ran this cell twice, accidentally trying to register a new env with the same id twice.')\n",
    "    print(\"Either change the id, or just continue, knowing your id was already registered\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f0e9f80",
   "metadata": {},
   "source": [
    "**Random actions run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southern-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")  # Load FrozenLake\n",
    "env.reset()\n",
    "\n",
    "for _ in range(5):\n",
    "    clear_output(wait=True) # Clears the previous output\n",
    "    a = env.render(mode=\"ansi\") \n",
    "    print(a)\n",
    "    action = env.action_space.sample()  \n",
    "    env.step(action) \n",
    "    time.sleep(0.5)\n",
    "env.close()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "scheduled-glasgow",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 2: \n",
    "\n",
    "Creating the Q-Learning Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-contest",
   "metadata": {},
   "source": [
    "Now that we validated the functionality of our function it is time to move on with the Q-Learning algorithm. \n",
    "\n",
    "Recall our Table is essentially a mapping of all possible state, action pairs and the expected reward for taking an action at a particular state that we will keep updating.\n",
    "\n",
    "\n",
    "$$Q(s_t,a_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e0f83",
   "metadata": {},
   "source": [
    "For our simple discrete Frozen Lake problem, this means we have 4 actions for columns, and 16 possible states (player location on the 4 by 4 grid). So our table will look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa8c3e",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "      <th></th>\n",
    "    <th>A0 - LEFT</th>\n",
    "    <th>A1 - DOWN</th>\n",
    "    <th>A2 - RIGHT</th>\n",
    "    <th>A3 - UP</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><strong>State 0</strong></td>\n",
    "    <td>Q(s,a)</td>\n",
    "    <td>Q(s,a)</td>\n",
    "      <td>Q(s,a)</td>\n",
    "      <td>Q(s,a)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td><strong>State 1</strong></td>\n",
    "    <td>Q(s,a)</td>\n",
    "    <td>Q(s,a)</td>\n",
    "    <td>Q(s,a)</td>\n",
    "      <td>Q(s,a)</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "      <td><strong>State ...</strong></td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "        <td>...</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "      <td><strong>State 15</strong></td>\n",
    "    <td>Q(s,a)</td>\n",
    "    <td>Q(s,a)</td>\n",
    "    <td>Q(s,a)</td>\n",
    "        <td>Q(s,a)</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec3a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c14e800e",
   "metadata": {},
   "source": [
    "**Initial Q-Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latter-header",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with very small values for all our Q(s,a)\n",
    "q_table = np.zeros([state_size, action_size])\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fe3323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55f9f3fa",
   "metadata": {},
   "source": [
    "#### PART 2.1:\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "The Q-Learning update functions will require hyperparameters. we'll define them here. Often the best place to choose a good starting value is reading publications or through experimentation. Unfortunately, its very difficult to give general advice, as most environments are radically different to each other, and often hyperparameter tuning is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8666bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is common to leave Hyperparameters in ALL CAPS to easily locate them\n",
    "\n",
    "EPOCHS = 20000  # number of epochs/episodes to train for\n",
    "ALPHA = 0.8 # aka the learning rate\n",
    "GAMMA = 0.95 # aka the discount rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fdd6e6",
   "metadata": {},
   "source": [
    "**Exploration vs. Exploitation Parameters**\n",
    "\n",
    "Basically how fast do we reduce epsilon. Reduce too fast, agent won't have enough time to learn. Reduce too slow, you're wasting time picking random actions. Key here is that these value help balance exploration (random choice) versus explotation (always picking what works for that Q(s,a). It's a tough balance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd70a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration vs. Exploitation parameters\n",
    "epsilon = 1.0                 # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "decay_rate = 0.001            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31d29c33",
   "metadata": {},
   "source": [
    "#### PART 2.2:\n",
    "Q-Table Update Functions Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-saturday",
   "metadata": {},
   "source": [
    "Now it is time to dive into the training / Q-Table update methodology. First we will define some functions needed for training phase:\n",
    "\n",
    "1. Action selection:\n",
    "\n",
    "* epsilon_greedy_action_selection: Is used to implement the epsilon greedy action selection routine.\n",
    "* compute_next_q_value: Computes the next Q-Values according to the formula from the lecture\n",
    "* reduce_epsilon: Reduces the $\\epsilon$ used for the epsilon greedy algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79070b6",
   "metadata": {},
   "source": [
    "**1. FUNCTION TO SELECT AN ACTION**\n",
    "\n",
    "If we simply always select the argmax() Q-table value during training, we'll most likely get stuck in an explotation loop, so we'll use a random value to randomly select an action from time to time, helping the model explore, rather than exploit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38439bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_selection(epsilon, q_table, discrete_state):\n",
    "    \"\"\"\n",
    "    Returns an action for the agent. Note how it uses a random number to decide on exploration \n",
    "    versus explotation trade-off.\n",
    "    \"\"\"\n",
    "    \n",
    "    random_number = np.random.random()\n",
    "    \n",
    "    # EXPLOITATION, USE BEST Q(s,a) Value\n",
    "    if random_number > epsilon:\n",
    "        # Action row for a particular state\n",
    "        state_row = q_table[discrete_state,:]\n",
    "\n",
    "        # Index of highest action for state\n",
    "        action = np.argmax(state_row, axis=0)\n",
    "            \n",
    "    # EXPLORATION, USE A RANDOM ACTION\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a4e89",
   "metadata": {},
   "source": [
    "**2. FUNCTION FOR Q_VALUE COMPUTATION**\n",
    "\n",
    "\n",
    "$$Q(s,a) \\gets (1-\\alpha)*Q(s,a) + \\alpha*[R(s,a) + \\gamma*\\max_{a}Q(s_{t+1}, a)]$$\n",
    "\n",
    "Here we have our main Q-Learning update equation, note how it takes in the old q-value, the next optimal q value, along with our current reward, and then updates the next q value accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ec3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_update(old_q_value, reward, next_optimal_q_value):\n",
    "    new_q = (1-ALPHA)*old_q_value +  ALPHA * (reward + GAMMA * next_optimal_q_value)\n",
    "    return new_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e05888",
   "metadata": {},
   "source": [
    "**3. FUNCTION TO REDUCE EPSILON**\n",
    "\n",
    "As training continues, we need to balance explotation versus exploration, we want ot make sure our agent doesn't get trapped in a cycle going from an square to another square back and forth. We also don't want our agent permanently choosing random values. We'll use the function below to try to balance this.\n",
    "\n",
    "$$ \\epsilon = \\epsilon_{min} + (\\epsilon_{max} - \\epsilon_{min})*e^{-\\lambda*\\tau}$$\n",
    "\n",
    "- $\\lambda$: decay rate\n",
    "- $\\tau$: epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c791f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_epsilon(epsilon,epoch):\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*epoch)\n",
    "    return epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68c42807",
   "metadata": {},
   "source": [
    "#### PART 2.3:\n",
    "\n",
    "Training of Agent and Updating Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d86c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset just in case\n",
    "q_table = np.zeros([state_size, action_size])\n",
    "total_reward = 0\n",
    "epsilon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080df6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of rewards\n",
    "rewards = []\n",
    "\n",
    "# Play 20k games\n",
    "for episode in range(EPOCHS):\n",
    "\n",
    "    # Reset the environment\n",
    "    env = gym.make(\"FrozenLakeNotSlippery-v0\")\n",
    "    # To visualize the whole traninig, change render_mode to \"human\" --> takes a lot of time\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = action_selection(epsilon, q_table, state)\n",
    "\n",
    "        # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "  \n",
    "        # Look up current/old qtable value Q(s_t,a_t)\n",
    "        old_q_value =  q_table[state,action]  \n",
    "\n",
    "        # Get the next optimal Q-Value\n",
    "        next_optimal_q_value = np.max(q_table[new_state, :])  \n",
    "\n",
    "        # Update q value\n",
    "        q_table[state,action] = q_update(old_q_value, reward, next_optimal_q_value)\n",
    "\n",
    "        total_rewards = total_rewards + reward\n",
    "        \n",
    "        # Our new state is state\n",
    "        state = new_state\n",
    "\n",
    "    episode += 1\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = reduce_epsilon(epsilon,episode) \n",
    "    rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08384087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x248fab14cd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(EPOCHS),np.cumsum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab364621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73509189, 0.77378094, 0.77378094, 0.73509189],\n",
       "       [0.73509189, 0.        , 0.81450625, 0.77378094],\n",
       "       [0.77378094, 0.857375  , 0.77378094, 0.81450625],\n",
       "       [0.81450625, 0.        , 0.77371249, 0.77366252],\n",
       "       [0.77378094, 0.81450625, 0.        , 0.73509189],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.        , 0.81450625],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.81450625, 0.        , 0.857375  , 0.77378094],\n",
       "       [0.81450625, 0.9025    , 0.9025    , 0.        ],\n",
       "       [0.857375  , 0.95      , 0.        , 0.857375  ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.95      , 0.857375  ],\n",
       "       [0.9025    , 0.95      , 1.        , 0.9025    ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e33b897",
   "metadata": {},
   "source": [
    "#### PART 2.4:\n",
    "Using Learned Q Table Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28938392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")\n",
    "state = env.reset()\n",
    "\n",
    "for _ in range(100):\n",
    "    a = env.render(mode=\"ansi\") \n",
    "    print(a)\n",
    "    \n",
    "    action = np.argmax(q_table[state])  # and chose action from the Q-Table\n",
    "    state, reward, done, info = env.step(action) # Finally perform the action\n",
    "\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ca95f0d",
   "metadata": {},
   "source": [
    "----\n",
    "### Part 3\n",
    "\n",
    "Q-Learning algorithm class programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a675a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Learning:\n",
    "    def __init__(self, gamma, epsilon, min_epsilon, epsilon_decay, n_actions, n_states):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.n_actions = n_actions\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.n_states = n_states\n",
    "        self.alpha = 0\n",
    "\n",
    "        self.Q = np.zeros([self.n_states, n_actions])\n",
    "        self.counts = np.zeros([self.n_states, n_actions])\n",
    "\n",
    "\n",
    "    def action_selection(self, observation):\n",
    "        \"\"\"\n",
    "        Returns an action for the agent. Note how it uses a random number to decide on exploration \n",
    "        versus explotation trade-off.\n",
    "        \"\"\"\n",
    "        random_number = np.random.random()\n",
    "        \n",
    "        # EXPLOITATION, USE BEST Q(s,a) Value\n",
    "        if random_number > self.epsilon:\n",
    "            # Action row for a particular state\n",
    "            state_row = self.Q[observation,:]\n",
    "            # Index of highest action for state\n",
    "            action = np.argmax(state_row, axis=0)\n",
    "\n",
    "        # EXPLORATION, USE A RANDOM ACTION\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def alpha_count(self,s,a):\n",
    "        self.counts[s,a] += 1\n",
    "        self.alpha = 1/self.counts[s,a]\n",
    "    \n",
    "    def reduce_epsilon(self,epoch):\n",
    "        if self.epsilon > self.min_epsilon:\n",
    "            self.epsilon = self.min_epsilon + (1. - self.min_epsilon)*np.exp(-self.epsilon_decay*epoch)\n",
    "    \n",
    "    def learn(self, state, state_, action, reward):\n",
    "        self.Q[state, action] = self.alpha*(reward + self.gamma*np.amax(self.Q[state_, :], axis=0) - self.Q[state, action])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a74109c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of rewards\n",
    "rewards = []\n",
    "Q = []\n",
    "agent = Q_Learning(GAMMA, max_epsilon, min_epsilon, decay_rate, action_size, state_size)\n",
    "\n",
    "# Play 20k games\n",
    "for episode in range(EPOCHS):\n",
    "\n",
    "    # Reset the environment\n",
    "    env = gym.make(\"FrozenLakeNotSlippery-v0\")\n",
    "    # To visualize the whole traninig, change render_mode to \"human\" --> takes a lot of time\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    \n",
    "    \n",
    "    while not done:\n",
    "        action = agent.action_selection(state)\n",
    "        # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        total_rewards += reward\n",
    "        agent.alpha_count(state, action)\n",
    "\n",
    "        # Learn step\n",
    "        agent.learn(state, new_state, action, reward)\n",
    "\n",
    "        # Our new state is state\n",
    "        state = new_state\n",
    "\n",
    "    episode += 1\n",
    "    Q = agent.Q\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    agent.reduce_epsilon(episode)\n",
    "    rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "650eac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x248fac25d00>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(EPOCHS),np.cumsum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab4c4173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21686887, 0.72010435, 0.16917335, 0.21521732],\n",
       "       [0.070764  , 0.        , 0.4150715 , 0.07935792],\n",
       "       [0.10778214, 0.68971187, 0.09431593, 0.22064286],\n",
       "       [0.26998084, 0.        , 0.09874516, 0.05676404],\n",
       "       [0.45505821, 0.80106838, 0.        , 0.27505747],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.87221629, 0.        , 0.31893106],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.66290187, 0.        , 0.85529644, 0.51751667],\n",
       "       [0.72145709, 0.90235594, 0.87817836, 0.        ],\n",
       "       [0.78988652, 0.94811881, 0.        , 0.6865503 ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.89418203, 0.95      , 0.83932815],\n",
       "       [0.89809756, 0.95      , 1.        , 0.89175913],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "815d3bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")\n",
    "state = env.reset()\n",
    "\n",
    "for _ in range(100):\n",
    "    a = env.render(mode=\"ansi\") \n",
    "    print(a)\n",
    "    \n",
    "    action = np.argmax(Q[state])  # and chose action from the Q-Table\n",
    "    state, reward, done, info = env.step(action) # Finally perform the action\n",
    "\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "20a9e06a1eee47c4abbed4ec8225ad91d78d9800d202b71b6b0a6e47016c6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

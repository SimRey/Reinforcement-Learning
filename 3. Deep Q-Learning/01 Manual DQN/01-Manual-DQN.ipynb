{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stopped-alberta",
   "metadata": {},
   "source": [
    "## <center>Manually Creating a DQN Model </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-porcelain",
   "metadata": {},
   "source": [
    "### Deep-Q-Learning\n",
    "In this notebook we will create our first Deep Reeinforcement Learning model, called Deep-Q-Network (DQN).\n",
    "We are again using a simple environment from openai gym. However, you will soon see the enormous gain we will get by switching from standard Q-Learning to Deep Q Learning.\n",
    "\n",
    "In this notebook we again take a look at the CartPole problem (https://gym.openai.com/envs/CartPole-v1/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from tensorflow.keras.models import Sequential, clone_model \n",
    "from tensorflow.keras.layers import Dense, InputLayer  \n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifty-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall():\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-exploration",
   "metadata": {},
   "source": [
    "Remember, the goal of the CartPole challenge was to balance the stick upright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southeast-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = recall()\n",
    "env.reset()\n",
    "\n",
    "for _ in range(9):\n",
    "    env.render(mode=\"human\")  \n",
    "    random_action = env.action_space.sample()\n",
    "    env.step(random_action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf18acd",
   "metadata": {},
   "source": [
    "### The Artificial Neural Network\n",
    "To build our network, we first need to find out how many actions and observation our environment has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "widespread-oxide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 possible actions and 4 observations\n"
     ]
    }
   ],
   "source": [
    "num_actions = env.action_space.n\n",
    "num_observations = env.observation_space.shape[0]  # You can use this command to get the number of observations\n",
    "print(f\"There are {num_actions} possible actions and {num_observations} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-alaska",
   "metadata": {},
   "source": [
    "So our network needs to have an input dimension of 4 and an output dimension of 2.\n",
    "In between we are free to chose.\n",
    "\n",
    "Let's just say we want to use a four layer architecture:\n",
    "\n",
    "\n",
    "1. The first layer has 16 neurons\n",
    "2. The second layer has 32 neurons\n",
    "4. The fourth layer (output layer) has 2 neurons\n",
    "\n",
    "This yields 690 parameters\n",
    "$$ \\text{4 observations} * 16 (\\text{neurons}) + 16 (\\text{bias}) + (16*32) + 32 + (32*2)+2 = 690$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "insured-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                80        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690\n",
      "Trainable params: 690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(num_observations, )))\n",
    "\n",
    "model.add(Dense(16,))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(num_actions))\n",
    "model.add(Activation('linear')) # used to chose one of the neurons\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-sitting",
   "metadata": {},
   "source": [
    "Now we have our model which takes an observation as input and outputs a value for each action.\n",
    "The higher the value, the more likely that this value is a suitable action for the current observation\n",
    "\n",
    "As stated in the lecture, Deep-Q-Learning works better when using a target network.\n",
    "So let's just copy the above network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advanced-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = clone_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7991ba",
   "metadata": {},
   "source": [
    "### Hyperparameters and Update Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interim-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "epsilon = 1.0\n",
    "EPSILON_REDUCE = 0.995  # is multiplied with epsilon each epoch to reduce it\n",
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-simple",
   "metadata": {},
   "source": [
    "Let us use the epsilon greedy action selection function once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coordinate-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_selection(model, epsilon, observation):\n",
    "    random_number = np.random.random()\n",
    "    if random_number > epsilon:\n",
    "        prediction = model.predict(observation.reshape(-1,4))  # perform the prediction on the observation\n",
    "        action = np.argmax(prediction)  # Chose the action with the higher value\n",
    "    else:\n",
    "        action = np.random.randint(0, env.action_space.n)  # Else use random action\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a10c4",
   "metadata": {},
   "source": [
    "----\n",
    "#### **Deque**\n",
    "\n",
    "A replay buffer is needed. We can use the **deque** data structure for this, which already implements the circular behavior. The *maxlen* argument specifies the number of elements the buffer can store between he overwrites them at the beginning. \n",
    "\n",
    "The following example shows how a **deque** works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brilliant-receptor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([0], maxlen=5)\n",
      "deque([0, 1], maxlen=5)\n",
      "deque([0, 1, 2], maxlen=5)\n",
      "deque([0, 1, 2, 3], maxlen=5)\n",
      "deque([0, 1, 2, 3, 4], maxlen=5)\n",
      "deque([1, 2, 3, 4, 5], maxlen=5)\n",
      "deque([2, 3, 4, 5, 6], maxlen=5)\n",
      "deque([3, 4, 5, 6, 7], maxlen=5)\n",
      "deque([4, 5, 6, 7, 8], maxlen=5)\n",
      "deque([5, 6, 7, 8, 9], maxlen=5)\n",
      "deque([6, 7, 8, 9, 10], maxlen=5)\n",
      "deque([6, 7, 8, 9, 10], maxlen=5)\n"
     ]
    }
   ],
   "source": [
    "deque_1 = deque(maxlen=5)\n",
    "for i in range(11):\n",
    "    deque_1.append(i)\n",
    "    print(deque_1)\n",
    "print(deque_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9880fbd",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-august",
   "metadata": {},
   "source": [
    "Let's say we allow our replay buffer a maximum size of 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thrown-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=20000)\n",
    "update_target_model = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c58c8",
   "metadata": {},
   "source": [
    "----\n",
    "#### **Unzipping and pairing**\n",
    "\n",
    "As mentioned in the lecture, action replaying is crucial for Deep Q-Learning. The following cell implements one version of the action replay algorithm. It uses the zip statement paired with the * (Unpacking Argument Lists) operator to create batches from the samples for efficient prediction and training. The zip statement returns all corresponding pairs from each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "constant-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 7) (2, 5, 8) (3, 6, 9)\n"
     ]
    }
   ],
   "source": [
    "test_tuple = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n",
    "zipped_list = list(zip(*test_tuple))\n",
    "a, b, c = zipped_list\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936e91d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-vegetation",
   "metadata": {},
   "source": [
    "Now it's time to write the replay function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scheduled-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(replay_buffer, batch_size, model, target_model):\n",
    "    \n",
    "    # As long as the buffer has not enough elements we do nothing\n",
    "    if len(replay_buffer) < batch_size: \n",
    "        return\n",
    "    \n",
    "    # Take a random sample from the buffer with size batch_size\n",
    "    samples = random.sample(replay_buffer, batch_size)  \n",
    "    \n",
    "    # to store the targets predicted by the target network for training\n",
    "    target_batch = []  \n",
    "    \n",
    "    # Efficient way to handle the sample by using the zip functionality\n",
    "    zipped_samples = list(zip(*samples))  \n",
    "    states, actions, rewards, new_states, dones = zipped_samples  \n",
    "    \n",
    "    # Predict targets for all states from the sample\n",
    "    targets = target_model.predict(np.array(states))\n",
    "    \n",
    "    # Predict Q-Values for all new states from the sample\n",
    "    q_values = model.predict(np.array(new_states))  \n",
    "    \n",
    "    # Now we loop over all predicted values to compute the actual targets\n",
    "    for i in range(batch_size):  \n",
    "        \n",
    "        # Take the maximum Q-Value for each sample\n",
    "        q_value = max(q_values[i])  \n",
    "        \n",
    "        # Store the ith target in order to update it according to the formula\n",
    "        target = targets[i].copy()  \n",
    "        if dones[i]:\n",
    "            target[actions[i]] = rewards[i]\n",
    "        else:\n",
    "            target[actions[i]] = rewards[i] + q_value * GAMMA\n",
    "        target_batch.append(target)\n",
    "\n",
    "    # Fit the model based on the states and the updated targets for 1 epoch\n",
    "    model.fit(np.array(states), np.array(target_batch), epochs=1, verbose=0)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-testing",
   "metadata": {},
   "source": [
    "We need to update our target network every once in a while. <br />\n",
    "Keras provides the *set_weights()* and *get_weights()* methods which do the work for us, so we only need to check whether we hit an update epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stainless-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_handler(epoch, update_target_model, model, target_model):\n",
    "    if epoch > 0 and epoch % update_target_model == 0:\n",
    "        target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4755d07",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-michael",
   "metadata": {},
   "source": [
    "Now it is time to write the training loop! <br />\n",
    "First we compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sharing-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "altered-interface",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lenovo\\Desktop\\Python\\Reinforcement Learning\\3. Deep Q-Learning\\01-Manual-DQN.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m# Clears the previous output\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Select action acc. to strategy\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m action \u001b[39m=\u001b[39m action_selection(model, epsilon, observation)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Perform action and get next state\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m next_observation, reward, done, \u001b[39m*\u001b[39minfo \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)  \n",
      "\u001b[1;32mc:\\Users\\Lenovo\\Desktop\\Python\\Reinforcement Learning\\3. Deep Q-Learning\\01-Manual-DQN.ipynb Cell 32\u001b[0m in \u001b[0;36maction_selection\u001b[1;34m(model, epsilon, observation)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m random_number \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m random_number \u001b[39m>\u001b[39m epsilon:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(observation\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m4\u001b[39;49m))  \u001b[39m# perform the prediction on the observation\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(prediction)  \u001b[39m# Chose the action with the higher value\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/01-Manual-DQN.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2029\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2027\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2028\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2029\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2030\u001b[0m   \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2031\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1193\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1193\u001b[0m   data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n\u001b[0;32m   1194\u001b[0m   \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[0;32m   1195\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:494\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m    493\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 494\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    497\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[0;32m    698\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:721\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(ds_variant):\n\u001b[0;32m    717\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource \u001b[39m=\u001b[39m (\n\u001b[0;32m    718\u001b[0m       gen_dataset_ops\u001b[39m.\u001b[39manonymous_iterator_v3(\n\u001b[0;32m    719\u001b[0m           output_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types,\n\u001b[0;32m    720\u001b[0m           output_shapes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_shapes))\n\u001b[1;32m--> 721\u001b[0m   gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3408\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3407\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3408\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3409\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[0;32m   3410\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3411\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_so_far = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    env = recall()\n",
    "    observation = env.reset() # Get inital state\n",
    "    \n",
    "    # Keras expects the input to be of shape [1, X] thus we have to reshape\n",
    "    done = False  \n",
    "    \n",
    "    points_epoch = []\n",
    "    points = 0\n",
    "    while not done:  # as long current run is active\n",
    "        clear_output(wait=True) # Clears the previous output\n",
    "\n",
    "        # Select action acc. to strategy\n",
    "        action = action_selection(model, epsilon, observation)\n",
    "        \n",
    "        # Perform action and get next state\n",
    "        next_observation, reward, done, *info = env.step(action)  \n",
    "\n",
    "        replay_buffer.append((observation, action, reward, next_observation, done))  # Update the replay buffer\n",
    "        observation = next_observation  # update the observation\n",
    "        points+=1\n",
    "\n",
    "        # Most important step! Training the model by replaying\n",
    "        replay(replay_buffer, BATCH_SIZE, model, target_model)\n",
    "\n",
    "    \n",
    "    epsilon *= EPSILON_REDUCE  # Reduce epsilon\n",
    "    \n",
    "    # Check if we need to update the target model\n",
    "    update_model_handler(epoch, update_target_model, model, target_model)\n",
    "\n",
    "\n",
    "    if points > best_so_far:\n",
    "        best_so_far = points\n",
    "\n",
    "    if epoch == 0 or epoch %10 == 0:\n",
    "        print(f\"{epoch}: Points reached: {points} - epsilon: {epsilon} - Best: {best_so_far}\")\n",
    "\n",
    "\n",
    "    # Breaking the training if no improvment\n",
    "    points_epoch.append(points)\n",
    "\n",
    "    if 150 <= epoch:\n",
    "        sample_points = points_epoch[-5:]\n",
    "        value = np.mean(sample_points)\n",
    "        if points < value:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e969bb",
   "metadata": {},
   "source": [
    "### Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d86cc628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "env = recall()\n",
    "observation = env.reset()\n",
    "points = 0\n",
    "for counter in range(300):\n",
    "    env.render(mode=\"human\")\n",
    "    points += 1\n",
    "    \n",
    "    # Get discretized observation\n",
    "    action = np.argmax(model.predict(observation.reshape(-1,4)))\n",
    "    \n",
    "    # Perform the action \n",
    "    observation, reward, done, *info = env.step(action) # Finally perform the action\n",
    "    \n",
    "    if done:\n",
    "        print(f\"Done, points: {points}\")\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "20a9e06a1eee47c4abbed4ec8225ad91d78d9800d202b71b6b0a6e47016c6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

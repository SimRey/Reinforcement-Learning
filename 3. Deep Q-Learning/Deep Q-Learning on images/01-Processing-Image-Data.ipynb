{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "720b88c8",
   "metadata": {},
   "source": [
    "## <center>Processing Images</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c2086",
   "metadata": {},
   "source": [
    "In this notebook, we will learn the steps of image preprocessing that are necessary for a deep agent to work properly on images. <br />\n",
    "As already mentioned in the last lecture, when dealing with image data, we often need to store multiple sequential frames in order to feed all available data to the agent. <br />\n",
    "It is not possible to decide whether a ball moves to the left or to the right given only a single image. <br />\n",
    "keras-rl provides a class called **Processor** which is used to process the image data before it gets fed into the backbone network\n",
    "\n",
    "Let us first start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62dd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # To handle images\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from rl.core import Processor  # To process the image within the keras-rl training routine\n",
    "from rl.memory import SequentialMemory  # To store the sequential frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81737b61",
   "metadata": {},
   "source": [
    "Let us first create an image based environment, namely the famous game called **Breakout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71628f9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find module 'c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\atari_py\\ale_interface\\ale_c.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lenovo\\Desktop\\Python\\Reinforcement Learning\\3. Deep Q-Learning\\Deep Q-Learning on images\\01-Processing-Image-Data.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/Desktop/Python/Reinforcement%20Learning/3.%20Deep%20Q-Learning/Deep%20Q-Learning%20on%20images/01-Processing-Image-Data.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m\"\u001b[39;49m\u001b[39mBreakout-v0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:142\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake\u001b[39m(\u001b[39mid\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39mmake(\u001b[39mid\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:87\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mMaking new env: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, path)\n\u001b[0;32m     86\u001b[0m spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspec(path)\n\u001b[1;32m---> 87\u001b[0m env \u001b[39m=\u001b[39m spec\u001b[39m.\u001b[39mmake(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m \u001b[39m# We used to have people override _reset/_step rather than\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m# reset/step. Set _gym_disable_underscore_compat = True on\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# your environment if you use these methods and don't want\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# compatibility code to be invoked.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(env, \u001b[39m\"\u001b[39m\u001b[39m_reset\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(env, \u001b[39m\"\u001b[39m\u001b[39m_step\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(env, \u001b[39m\"\u001b[39m\u001b[39m_gym_disable_underscore_compat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:58\u001b[0m, in \u001b[0;36mEnvSpec.make\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentry_point(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n\u001b[0;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m load(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mentry_point)\n\u001b[0;32m     59\u001b[0m     env \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n\u001b[0;32m     61\u001b[0m \u001b[39m# Make the enviroment aware of which spec it came from.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:17\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(name):\n\u001b[0;32m     16\u001b[0m     mod_name, attr_name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     mod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(mod_name)\n\u001b[0;32m     18\u001b[0m     fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(mod, attr_name)\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m fn\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\gym\\envs\\atari\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39matari\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39matari_env\u001b[39;00m \u001b[39mimport\u001b[39;00m AtariEnv\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgym\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m seeding\n\u001b[0;32m      8\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39matari_py\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     11\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mDependencyNotInstalled(\n\u001b[0;32m     12\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. (HINT: you can install Atari dependencies by running \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install gym[atari]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e))\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\atari_py\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39male_python_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgames\u001b[39;00m \u001b[39mimport\u001b[39;00m get_game_path, list_games\n\u001b[0;32m      4\u001b[0m \u001b[39m# default to only logging errors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\atari_py\\ale_python_interface.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     ale_lib \u001b[39m=\u001b[39m cdll\u001b[39m.\u001b[39mLoadLibrary(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39m),\n\u001b[0;32m     15\u001b[0m                                             \u001b[39m'\u001b[39m\u001b[39male_interface/libale_c.so\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     16\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     ale_lib \u001b[39m=\u001b[39m cdll\u001b[39m.\u001b[39;49mLoadLibrary(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mdirname(\u001b[39m__file__\u001b[39;49m),\n\u001b[0;32m     18\u001b[0m                                             \u001b[39m'\u001b[39;49m\u001b[39male_interface/ale_c.dll\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     20\u001b[0m ale_lib\u001b[39m.\u001b[39mALE_new\u001b[39m.\u001b[39margtypes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     21\u001b[0m ale_lib\u001b[39m.\u001b[39mALE_new\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m c_void_p\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\ctypes\\__init__.py:460\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLoadLibrary\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dlltype(name)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\lib\\ctypes\\__init__.py:382\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[0;32m    383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\atari_py\\ale_interface\\ale_c.dll' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6cc5b",
   "metadata": {},
   "source": [
    "We need to decide how many sequential frames are necessary to capture all information.<br/>\n",
    "Let's go with 3.<br/>\n",
    "This is also called window_length, which we need to pass to the **SequentialMemory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80976270",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_LENGTH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4044a9c",
   "metadata": {},
   "source": [
    "What replay memory effectively does, is that it appends WINDOW_LENGTH sequential frames to a list and then appends this whole list to the memory.\n",
    "Thus a single element from our SequentialMemory contains WINDOW_LENGTH (consecutive images) <br />\n",
    "The code snipped below demonstrates a basic implementation of this routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7667fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "env.reset()\n",
    "\n",
    "sequential_frame_buffer = []  # Our actual memory\n",
    "\n",
    "# Temporary storage to capture sequential frames which can store a max of WINDOW_LENGTH images\n",
    "temp_sequential_frames = deque(maxlen=WINDOW_LENGTH)\n",
    "\n",
    "for i in range(10):\n",
    "    action = 3  # always go left, to visualize the movement (action 3)\n",
    "    observation, r, d, info = env.step(action)  # and perform it on the environment to get the next state\n",
    "    \n",
    "    # We have to wait until the deque is full (so it contains exactly WINDOW_LENGTH images)\n",
    "    if len(temp_sequential_frames) == WINDOW_LENGTH: \n",
    "        # If the deque is full we know that it contains WINDOW_LENGTH frames and we append those frames\n",
    "        # to our actual memory\n",
    "        sequential_frame_buffer.append(list(temp_sequential_frames))\n",
    "    \n",
    "    # Update the deque\n",
    "    temp_sequential_frames.append(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab64670",
   "metadata": {},
   "source": [
    "We can now plot the consecutive images stored in each timestep. <br />\n",
    "Each row visualizes one element of our *sequential_frame_buffer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axis = plt.subplots(4, WINDOW_LENGTH, figsize=(12, 12))\n",
    "\n",
    "for global_index, timestep in enumerate(sequential_frame_buffer[:4]):\n",
    "    for frame_index, frame in enumerate(timestep):\n",
    "        axis[global_index][frame_index].imshow(frame)\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e1046",
   "metadata": {},
   "source": [
    "Of course we do not have to do this by ourselves as keras-rl does it automatically if WINDOW_LENGTH is larger than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does the same thing in a much more optimized way\n",
    "memory = SequentialMemory(limit=1000, window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb9978",
   "metadata": {},
   "source": [
    "Besides that we need to decide how large our images should be. <br />\n",
    "Larger images might contain more information but also increase the training time. <br />\n",
    "Let us use an image size of $84\\times84$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (84, 84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69af7c1",
   "metadata": {},
   "source": [
    "Now we can create image processing class, which inherits the **Processor** provided by keras-rl (https://github.com/keras-rl/keras-rl/blob/master/rl/core.py#L515)\n",
    "\n",
    "Each processor can define the following methods:\n",
    "1. *process_step(observation, reward, done, info)* (\"Processes an entire step by applying the processor to the observation, reward, and info arguments\". Used during inference)\n",
    "2. *process_observation(observation)* (\"Processes the observation as obtained from the environment for use in an agent and returns it\")\n",
    "3. *process_reward(reward)* (\"Processes the reward as obtained from the environment for use in an agent and returns it\")\n",
    "4. *process_info(info)* (\"Processes the info as obtained from the environment for use in an agent and returns it)\n",
    "5. *process_action(action)* (\"Processes an action predicted by an agent but before execution in an environment\")\n",
    "6. *process_state_batch(batch)* (\"Processes an entire batch of states and returns it\". Used for training)\n",
    "\n",
    "The overall use of the processor is to act as a \"translator\" which translates the observation provided by gym into something our network can handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecd61d",
   "metadata": {},
   "source": [
    "Let's define our first processor, called **BreakOutProcessor**\n",
    "As we do not train in this notebook, we only overwrite the *process_observation* function. <br />\n",
    "This function has to perform two operations:\n",
    "1. Resize the image to our desired shape\n",
    "2. Convert it to grayscale (as the colored images do not yield any more information in this case)\n",
    "We will use PIL to perform those tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreakOutProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        # First convert the numpy array to a PIL Image\n",
    "        img = Image.fromarray(observation)\n",
    "        # Then resize the image\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        # And convert it to grayscale  (The L stands for luminance)\n",
    "        img = img.convert(\"L\")\n",
    "        # Finally we convert the image back to a numpy array and return it\n",
    "        return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7b3d6",
   "metadata": {},
   "source": [
    "We can now try the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e976e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = []\n",
    "breakout_proc = BreakOutProcessor()\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    action = env.action_space.sample()  # sample a random action\n",
    "    observation, r, d, info = env.step(action)  # and perform it on the environment to get the next state\n",
    "    processed_observation = breakout_proc.process_observation(observation)\n",
    "    sample_images.append(processed_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d91dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the original observation is {observation.shape} \" \\\n",
    "        f\"and the shape of the processed observation is {processed_observation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782b46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(sample_images[-1], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f8f2f",
   "metadata": {},
   "source": [
    "Now we have a full image processing pipeline which we can use in the next notebook to process the images for training "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "20a9e06a1eee47c4abbed4ec8225ad91d78d9800d202b71b6b0a6e47016c6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
